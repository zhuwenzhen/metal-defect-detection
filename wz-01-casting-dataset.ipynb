{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b1a88e",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59721e33",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 1. Get the casting data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66b87f6f",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://castings/Castings.zip to ./Castings.zip              \n"
     ]
    }
   ],
   "source": [
    "## S3 -> local\n",
    "# ! cd /home/ec2-user/SageMaker/saman-team/ \\\n",
    "# && aws s3 cp s3://castings/Castings.zip . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea00e9a",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# ! cd /home/ec2-user/SageMaker/saman-team/ && unzip Castings.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b92a1",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 2. Use the `gdxray` to convert dataset\n",
    "\n",
    "> Use `TensorFlow` kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1fdcea7",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# ! rm -r /home/ec2-user/SageMaker/saman-team/Castings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b616d0",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0, \"/home/ec2-user/SageMaker/saman-team/metal-defect-detection\")\n",
    "# import gdxray\n",
    "\n",
    "# dataset.load_gdxray(DATA_DIR, \"train\", \"Castings\", auto_download=True)\n",
    "# # Must call before using the dataset\n",
    "# dataset.prepare()\n",
    "\n",
    "# print(\"Image Count: {}\".format(len(dataset.image_ids)))\n",
    "# print(\"Class Count: {}\".format(dataset.num_classes))\n",
    "# for i, info in enumerate(dataset.class_info):\n",
    "#     print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7b62a1",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "Finished downloading datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/ec2-user/SageMaker/saman-team/metal-defect-detection\")\n",
    "import gdxray\n",
    "\n",
    "dataset = gdxray.XrayDataset()\n",
    "DATA_DIR = \"/home/ec2-user/SageMaker/saman-team\"\n",
    "train_labels = dataset.gdxray2cocoJSON(DATA_DIR, \"train\", \"Castings\", auto_download=True, output_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af1b073b",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_imgs = []\n",
    "for entry in train_labels[\"images\"]:\n",
    "    train_imgs.append(entry[\"file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a05fd3",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_imgs = []\n",
    "for entry in test_labels[\"images\"]:\n",
    "    test_imgs.append(entry[\"file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962503d9",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad533bdc",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0a3b70",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished downloading datasets\n"
     ]
    }
   ],
   "source": [
    "test_labels = dataset.gdxray2cocoJSON(DATA_DIR, \"test\", \"Castings\", auto_download=True, output_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ac8cddc",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from glob import glob\n",
    "\n",
    "def setup_train_test(dataset_root_dir, train_files, test_files):\n",
    "    train_dir = os.path.join(dataset_root_dir, \"train\")\n",
    "    test_dir = os.path.join(dataset_root_dir, \"test\")\n",
    "    \n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    raw_dir =  os.path.join(dataset_root_dir, \"Castings\")\n",
    "    all_imgs = sorted([y for x in os.walk(raw_dir) for y in glob(os.path.join(x[0], '*.png'))])\n",
    "    #all_imgs = all_imgs\n",
    "#     print(all_imgs)\n",
    "    for img_path in all_imgs:\n",
    "        #print(img_path)\n",
    "        key = '/'.join(img_path.split(\"/\")[-3:])\n",
    "        print(key)\n",
    "        if key in train_files:\n",
    "            shutil.copy(img_path, train_dir)\n",
    "            print(f\"copying from {img_path} to {train_dir}\")\n",
    "        if key in test_files:\n",
    "            shutil.copy(img_path, test_dir)\n",
    "            print(f\"copying from {img_path} to {test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198661cf",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "setup_train_test(DATA_DIR, train_imgs, test_imgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
